{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Week_5_Lab1_Text_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SalmanRafiullah/EAI6000/blob/master/Week_5_Lab1_Text_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q7Otd3zXN_u6"
      },
      "source": [
        "## Week 5 Lab - Text embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GE91qWZkm8ZQ"
      },
      "source": [
        "##### Based in part on Tutorial by TensorFlow Authors\n",
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7SN5USFEIIK3"
      },
      "source": [
        "# Word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q6mJg1g3apaz"
      },
      "source": [
        "This lab introduces word embeddings. It contains complete code to train word embeddings from scratch on a small dataset, and to visualize these embeddings using the [Embedding Projector](http://projector.tensorflow.org).\n",
        "\n",
        "\n",
        "### Word embeddings\n",
        "\n",
        "Word embeddings give us a way to use an efficient, dense representation in which similar words have a similar encoding. Importantly, we do not have to specify this encoding by hand. An embedding is a dense vector of floating point values (the length of the vector is a parameter you specify). Instead of specifying the values for the embedding manually, they are trainable parameters (weights learned by the model during training, in the same way a model learns weights for a dense layer). It is common to see word embeddings that are 8-dimensional (for small datasets), up to 1024-dimensions when working with large datasets. A higher dimensional embedding can capture fine-grained relationships between words, but takes more data to learn.\n",
        "\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/images/embedding2.png?raw=1\" alt=\"Diagram of an embedding\" width=\"400\"/>\n",
        "\n",
        "Above is a diagram for a word embedding. Each word is represented as a 4-dimensional vector of floating point values. Another way to think of an embedding is as \"lookup table\". After these weights have been learned, we can encode each word by looking up the dense vector it corresponds to in the table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SZUQErGewZxE"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SIXEk5ON5P7h",
        "outputId": "ab9f222e-56b8-4083-e752-0d3e32d78553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  !pip install tf-nightly\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.enable_eager_execution()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-nightly in /usr/local/lib/python3.6/dist-packages (2.2.0.dev20200319)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.9.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.4.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.3.3)\n",
            "Requirement already satisfied: tb-nightly<2.3.0a0,>=2.2.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.2.0a20200321)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: tf-estimator-nightly in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.3.0.dev2020032101)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.18.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.21.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.7.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (46.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.6.0.post2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.4.8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RutaI-Tpev3T",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eqBazMiVQkj1"
      },
      "source": [
        "## Using the Embedding layer\n",
        "\n",
        "Keras makes it easy to use word embeddings. Let's take a look at the [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer.\n",
        "\n",
        "The Embedding layer can be understood as a lookup table that maps from integer indices (which stand for specific words) to dense vectors (their embeddings). The dimensionality (or width) of the embedding is a parameter you can experiment with to see what works well for your problem, much in the same way you would experiment with the number of neurons in a Dense layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-OjxLVrMvWUE",
        "colab": {}
      },
      "source": [
        "embedding_layer = layers.Embedding(1000, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2dKKV1L2Rk7e"
      },
      "source": [
        "\n",
        "\n",
        "When you create an Embedding layer, the weights for the embedding are randomly initialized (just like any other layer). During training, they are gradually adjusted via backpropagation. Once trained, the learned word embeddings will roughly encode similarities between words (as they were learned for the specific problem your model is trained on).\n",
        "\n",
        "If you pass an integer to an embedding layer, the result replaces each integer with the vector from the embedding table:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0YUjPgP7w0PO",
        "outputId": "1787b634-6f56-4896-fdcc-2b69e5e853fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "result = embedding_layer(tf.constant([1,2,3]))\n",
        "result.numpy()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00805939,  0.04685341,  0.01989469, -0.0273659 , -0.00701939],\n",
              "       [-0.03947519, -0.04944763, -0.03775787,  0.01367908, -0.02507417],\n",
              "       [-0.02237641, -0.01090001, -0.04974532, -0.03846005,  0.04521826]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O4PC4QzsxTGx"
      },
      "source": [
        "For text or sequence problems, the Embedding layer takes a 2D tensor of integers, of shape `(samples, sequence_length)`, where each entry is a sequence of integers. It can embed sequences of variable lengths. You could feed into the embedding layer above batches with shapes `(32, 10)` (batch of 32 sequences of length 10) or `(64, 15)` (batch of 64 sequences of length 15).\n",
        "\n",
        "The returned tensor has one more axis than the input, the embedding vectors are aligned along the new last axis. Pass it a `(2, 3)` input batch and the output is `(2, 3, N)`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vwSYepRjyRGy",
        "outputId": "cc9140d1-0226-4bcf-8fea-e90158ede4fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result = embedding_layer(tf.constant([[0,1,2],[3,4,5]]))\n",
        "result.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(2), Dimension(3), Dimension(5)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0r-OsQ-609BZ",
        "colab_type": "code",
        "outputId": "529fc643-4fae-434c-8e33-e6ee3928cd34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "result.numpy()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.02186915, -0.03974701, -0.01663443,  0.04413409,\n",
              "         -0.00249145],\n",
              "        [ 0.00805939,  0.04685341,  0.01989469, -0.0273659 ,\n",
              "         -0.00701939],\n",
              "        [-0.03947519, -0.04944763, -0.03775787,  0.01367908,\n",
              "         -0.02507417]],\n",
              "\n",
              "       [[-0.02237641, -0.01090001, -0.04974532, -0.03846005,\n",
              "          0.04521826],\n",
              "        [-0.0107555 ,  0.00203545,  0.02690581, -0.00812675,\n",
              "         -0.02030816],\n",
              "        [ 0.03230271, -0.03150377,  0.04149586,  0.00710667,\n",
              "          0.03244491]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WGQp2N92yOyB"
      },
      "source": [
        "When given a batch of sequences as input, an embedding layer returns a 3D floating point tensor, of shape `(samples, sequence_length, embedding_dimensionality)`. To convert from this sequence of variable length to a fixed representation there are a variety of standard approaches. You could use an RNN, Attention, or pooling layer before passing it to a Dense layer. This tutorial uses pooling because it's simplest. The [Text Classification with an RNN](text_classification_rnn.ipynb) tutorial is a good next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aGicgV5qT0wh"
      },
      "source": [
        "## Learning embeddings from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Bh8B1TUT6mV"
      },
      "source": [
        "In this lab you will train a sentiment classifier on IMDB movie reviews. In the process, the model will learn embeddings from scratch. We will use to a preprocessed dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yg6tyxPtp1TE",
        "outputId": "6d5fae88-bebf-4969-8d80-efb0201eaae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "(train_data, test_data), info = tfds.load(\n",
        "    'imdb_reviews/subwords8k', \n",
        "    split = (tfds.Split.TRAIN, tfds.Split.TEST), \n",
        "    with_info=True, as_supervised=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x7f23c160f1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x7f23c160f1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <function _get_dataset_from_filename at 0x7f23c160f1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\n",
            "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\n",
            "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\n",
            "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x7f23c160f1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x7f23c160f1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <function _get_dataset_from_filename at 0x7f23c160f1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\n",
            "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\n",
            "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\n",
            "})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jjnBsFXaLVPL"
      },
      "source": [
        "Get the encoder (`tfds.features.text.SubwordTextEncoder`), and have a quick look at the vocabulary. \n",
        "\n",
        "The \"\\_\" in the vocabulary represent spaces. Note how the vocabulary includes whole words (ending with \"\\_\") and partial words which it can use to build larger words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MYrsTgxhLBfl",
        "outputId": "422ba5d7-f307-42cc-83bc-bc894ecd9acd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "encoder = info.features['text'].encoder\n",
        "encoder.subwords[:20]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the_',\n",
              " ', ',\n",
              " '. ',\n",
              " 'a_',\n",
              " 'and_',\n",
              " 'of_',\n",
              " 'to_',\n",
              " 's_',\n",
              " 'is_',\n",
              " 'br',\n",
              " 'in_',\n",
              " 'I_',\n",
              " 'that_',\n",
              " 'this_',\n",
              " 'it_',\n",
              " ' /><',\n",
              " ' />',\n",
              " 'was_',\n",
              " 'The_',\n",
              " 'as_']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GwCTfSG63Qth"
      },
      "source": [
        "Movie reviews can be different lengths. We will use the `padded_batch` method to standardize the lengths of the reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LwSCxER_2Lef",
        "colab": {}
      },
      "source": [
        "padded_shapes = ([None],())\n",
        "train_batches = train_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes)\n",
        "test_batches = test_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dF8ORMt2U9lj"
      },
      "source": [
        "As imported, the text of reviews is integer-encoded (each integer represents a specific word or word-part in the vocabulary).\n",
        "\n",
        "Note the trailing zeros, because the batch is padded to the longest example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Se-phCknsoan",
        "outputId": "b5629d16-ad48-4f8a-9b7c-d638a4821a7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "train_batch, train_labels = next(iter(train_batches))\n",
        "train_batch.numpy()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  12,  853,  143, ...,    0,    0,    0],\n",
              "       [  12,  305,  284, ...,    0,    0,    0],\n",
              "       [3621, 3724, 7961, ..., 7961,  615, 7975],\n",
              "       ...,\n",
              "       [  19,  457,  240, ...,    0,    0,    0],\n",
              "       [7915, 7961,  989, ...,    0,    0,    0],\n",
              "       [1455,    1,  228, ...,    0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zI9_wLIiWO8Z"
      },
      "source": [
        "### Create a simple model\n",
        "\n",
        "We will use the [Keras Sequential API](../../guide/keras) to define our model. In this case it is a \"Continuous bag of words\" style model.\n",
        "\n",
        "* Next the Embedding layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: `(batch, sequence, embedding)`.\n",
        "\n",
        "* Next, a GlobalAveragePooling1D layer returns a fixed-length output vector for each example by averaging over the sequence dimension. This allows the model to handle input of variable length, in the simplest way possible.\n",
        "\n",
        "* This fixed-length output vector is piped through a fully-connected (Dense) layer with 16 hidden units.\n",
        "\n",
        "* The last layer is densely connected with a single output node. Using the sigmoid activation function, this value is a float between 0 and 1, representing a probability (or confidence level) that the review is positive.\n",
        "\n",
        "Caution: This model doesn't use masking, so the zero-padding is used as part of the input, so the padding length may affect the output.  To fix this, see the [masking and padding guide](../../guide/keras/masking_and_padding)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pHLcFtn5Wsqj",
        "outputId": "1898a682-8b6e-45ae-fdb9-14c81f75bcc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "embedding_dim=16\n",
        "\n",
        "model = keras.Sequential([\n",
        "  layers.Embedding(encoder.vocab_size, embedding_dim),\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dense(16, activation='relu'),\n",
        "  layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 16)          130960    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 131,249\n",
            "Trainable params: 131,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tgLcXzktRZA6"
      },
      "source": [
        "## Review questions on embedding model\n",
        "1. What is encoder.vocab_size? What does this number represent? What happens in an input has a word that is not in the encoder vocab?\n",
        "2. What is the embedding dimension? What does this number represent? \n",
        "3. What are the benefits and drawbacks of having a larger embedding dimensionality?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPwuw_WR21HZ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        ">1. The vocab size defines the hashing space from which words are hashed. The model will not be able to assign weight to the OOV word and may throw random values.\n",
        "2. Embedding dimension is a low dimensional space into which a high dimensional vector can be translated into.\n",
        "3. It requires a lot of space taking out the advantage of out of core computing and increasing the computing time. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JjLNgKO7W2fe"
      },
      "source": [
        "### Compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNCzZ_VB3ymM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "855e266c-e540-40b4-bddb-0015ed1e5a80"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_batches,\n",
        "    epochs=10,\n",
        "    validation_data=test_batches, validation_steps=20)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f23420ae950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f23420ae950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f23420ae950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "2500/2500 [==============================] - 23s 9ms/step - loss: 0.5001 - acc: 0.7012 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
            "Epoch 2/10\n",
            "2500/2500 [==============================] - 17s 7ms/step - loss: 0.2767 - acc: 0.8850 - val_loss: 0.4182 - val_acc: 0.8500\n",
            "Epoch 3/10\n",
            "2500/2500 [==============================] - 17s 7ms/step - loss: 0.2199 - acc: 0.9124 - val_loss: 0.4589 - val_acc: 0.8550\n",
            "Epoch 4/10\n",
            "2500/2500 [==============================] - 17s 7ms/step - loss: 0.1866 - acc: 0.9269 - val_loss: 0.5096 - val_acc: 0.8550\n",
            "Epoch 5/10\n",
            "2500/2500 [==============================] - 17s 7ms/step - loss: 0.1631 - acc: 0.9369 - val_loss: 0.5639 - val_acc: 0.8400\n",
            "Epoch 6/10\n",
            "2500/2500 [==============================] - 17s 7ms/step - loss: 0.1447 - acc: 0.9462 - val_loss: 0.6281 - val_acc: 0.8350\n",
            "Epoch 7/10\n",
            "2500/2500 [==============================] - 17s 7ms/step - loss: 0.1295 - acc: 0.9538 - val_loss: 0.6960 - val_acc: 0.8350\n",
            "Epoch 8/10\n",
            "2500/2500 [==============================] - 17s 7ms/step - loss: 0.1167 - acc: 0.9596 - val_loss: 0.7689 - val_acc: 0.8350\n",
            "Epoch 9/10\n",
            "2500/2500 [==============================] - 17s 7ms/step - loss: 0.1059 - acc: 0.9642 - val_loss: 0.8446 - val_acc: 0.8400\n",
            "Epoch 10/10\n",
            "2500/2500 [==============================] - 17s 7ms/step - loss: 0.0963 - acc: 0.9691 - val_loss: 0.9420 - val_acc: 0.8350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LQjpKVYTXU-1"
      },
      "source": [
        "## Evaluating the model\n",
        "1. Plot the training and validiation accuracy as a function of training epoch. When does the model start overfitting?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0D3OTmOT1z1O",
        "outputId": "657f514b-8081-4226-af20-1ff6358a40a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#Define plot space\n",
        "fig, ax = plt.subplots()\n",
        "#Plot training loss\n",
        "plt.plot(history.history['loss'], marker = '.', label = 'Training loss')\n",
        "#Plot validation loss\n",
        "plt.plot(history.history['val_loss'], marker = '.', label = 'Validation loss')\n",
        "#Set y label\n",
        "plt.ylabel('Loss')\n",
        "#Set x label\n",
        "plt.xlabel('Epoch')\n",
        "#Display legend\n",
        "plt.legend(loc='lower left')\n",
        "#Set xticks to start from 1\n",
        "plt.xticks(np.arange(len(history.history['loss'])),np.arange(len(history.history['loss'])+1)[1:])\n",
        "#Set plt title\n",
        "plt.title('Variation of loss with number of Epochs')\n",
        "#Display plot\n",
        "plt.show;"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATVy3bzX06G7",
        "colab_type": "code",
        "outputId": "2d53ee8b-a945-4b26-d265-59e3ccb47c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "#Define plot space\n",
        "fig, ax = plt.subplots()\n",
        "#Plot training accuracy\n",
        "plt.plot(history.history['acc'], marker = '.', label = 'Training accuracy')\n",
        "#Plot validation accuracy\n",
        "plt.plot(history.history['val_acc'], marker = '.', label = 'Validation accuracy')\n",
        "#Set y label\n",
        "plt.ylabel('Accuracy')\n",
        "#Set x label\n",
        "plt.xlabel('Epochs')\n",
        "#Set plot title\n",
        "plt.title('Variation of model accuracy with number of Epochs')\n",
        "#Place legend on top left\n",
        "plt.legend(loc='lower right')\n",
        "#Set xlabels to start from 1\n",
        "plt.xticks(np.arange(len(history.history['acc'])),np.arange(len(history.history['acc'])+1)[1:])\n",
        "#show the plot\n",
        "plt.show;"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndU8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JZ_4kl8IbvS",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> The model starts overfitting after the 7th Epoch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KCoA6qwqP836"
      },
      "source": [
        "## Retrieve the learned embeddings\n",
        "\n",
        "Next, let's retrieve the word embeddings learned during training. This will be a matrix of shape `(vocab_size, embedding-dimension)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t8WwbsXCXtpa",
        "outputId": "7ff7126c-554b-4c76-cf57-6f8ab122e818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "e = model.layers[0]\n",
        "weights = e.get_weights()[0]\n",
        "print(weights.shape) # shape: (vocab_size, embedding_dim)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8185, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J8MiCA77X8B8"
      },
      "source": [
        "We will now write the weights to disk. To use the [Embedding Projector](http://projector.tensorflow.org), we will upload two files in tab separated format: a file of vectors (containing the embedding), and a file of meta data (containing the words)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GsjempweP9Lq",
        "colab": {}
      },
      "source": [
        "import io\n",
        "\n",
        "encoder = info.features['text'].encoder\n",
        "\n",
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for num, word in enumerate(encoder.subwords):\n",
        "  vec = weights[num+1] # skip 0, it's padding.\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JQyMZWyxYjMr"
      },
      "source": [
        "If you are running this tutorial in [Colaboratory](https://colab.research.google.com), you can use the following snippet to download these files to your local machine (or use the file browser, *View -> Table of contents -> File browser*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-gFbbMmvYvhp",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PXLfFA54Yz-o"
      },
      "source": [
        "## Visualize the embeddings\n",
        "\n",
        "To visualize our embeddings we will upload them to the embedding projector.\n",
        "\n",
        "Open the [Embedding Projector](http://projector.tensorflow.org/) (this can also run in a local TensorBoard instance).\n",
        "\n",
        "* Click on \"Load data\".\n",
        "\n",
        "* Upload the two files we created above: `vecs.tsv` and `meta.tsv`.\n",
        "\n",
        "The embeddings you have trained will now be displayed. You can search for words to find their closest neighbors. For example, try searching for \"beautiful\". You may see neighbors like \"wonderful\". \n",
        "\n",
        "Note: your results may be a bit different, depending on how weights were randomly initialized before training the embedding layer.\n",
        "\n",
        "Note: experimentally, you may be able to produce more interpretable embeddings by using a simpler model. Try deleting the `Dense(16)` layer, retraining the model, and visualizing the embeddings again.\n",
        "\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/images/embedding.jpg?raw=1\" alt=\"Screenshot of the embedding projector\" width=\"400\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EKQ2lrhTS6hH"
      },
      "source": [
        "## Embedding visualizaton questions\n",
        "1. Load the embedding into the visualizer and search for 4 different words. For each, list the 5 closest neighbors (these are output by the visualizer after you search for a word. Use euclidean distance option). Are these what you would expect for the closest neighbors? Why do you think the embedding for some words is difficult to interpret?\n",
        "2. Compare the closest neighbors from these same words to the Word2Vec 10k pretrained embedding (available on the visualizer).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhO-urvaqi8O",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> 1. Beautiful\n",
        "    1. Rich\n",
        "    1. Witty\n",
        "    1. rk\n",
        "    1. Asto\n",
        "    1. Park\n",
        "1. Comparison\n",
        "    1. Happen\n",
        "    1. Pyhsical\n",
        "    1. William\n",
        "    1. Moment\n",
        "    1. Episodes\n",
        "1. House\n",
        "    1. Isol\n",
        "    1. Himself\n",
        "    1. An\n",
        "    1. See\n",
        "    1. Comedy\n",
        "1. Life\n",
        "    1. Sop\n",
        "    1. Han\n",
        "    1. Treatment\n",
        "    1. Sing\n",
        "    1. ik\n",
        "\n",
        "The embeddings are difficult to interpret becuase the model has learned different connections between the words than what the brain is trained for.\n",
        "Maybe the model needs to go through many more words to be ablet o get the connections right.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v_XWMn5JsVsz"
      },
      "source": [
        "## Bonus Question\n",
        "Modify the embedding model and/or neural network to improve the accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1_94CdZ3q5A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "2ada54c8-3f9b-4caa-8c73-697cf93e3e13"
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "embedding_dim=16\n",
        "\n",
        "model = keras.Sequential([\n",
        "  layers.Embedding(encoder.vocab_size, embedding_dim),\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
        "  layers.Dropout(0.1),\n",
        "  layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 16)          130960    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 131,249\n",
            "Trainable params: 131,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lCUgdP69Wzix",
        "outputId": "7645d88c-42e2-4115-9429-15a3fd5b9837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_batches,\n",
        "    epochs=10,\n",
        "    validation_data=test_batches, validation_steps=20)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f234177f8c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f234177f8c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f234177f8c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "2500/2500 [==============================] - 22s 9ms/step - loss: 0.6644 - acc: 0.5403 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
            "Epoch 2/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.4997 - acc: 0.7697 - val_loss: 0.4625 - val_acc: 0.7850\n",
            "Epoch 3/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.4038 - acc: 0.8396 - val_loss: 0.4181 - val_acc: 0.8400\n",
            "Epoch 4/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.3559 - acc: 0.8636 - val_loss: 0.4029 - val_acc: 0.8500\n",
            "Epoch 5/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.3267 - acc: 0.8778 - val_loss: 0.3946 - val_acc: 0.8600\n",
            "Epoch 6/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.3084 - acc: 0.8847 - val_loss: 0.3849 - val_acc: 0.8500\n",
            "Epoch 7/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.2902 - acc: 0.8937 - val_loss: 0.3913 - val_acc: 0.8500\n",
            "Epoch 8/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.2794 - acc: 0.8960 - val_loss: 0.3864 - val_acc: 0.8500\n",
            "Epoch 9/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.2689 - acc: 0.9008 - val_loss: 0.3901 - val_acc: 0.8500\n",
            "Epoch 10/10\n",
            "2500/2500 [==============================] - 16s 6ms/step - loss: 0.2631 - acc: 0.9024 - val_loss: 0.3912 - val_acc: 0.8500\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}